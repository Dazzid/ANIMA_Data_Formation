{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114792b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Successfully imported convention\n",
      "Successfully imported chord_mapping\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell implements the full MIDI-to-53TET conversion logic, including a comprehensive\n",
    "Chord Mapping engine that translates 12-TET chord qualities into their 53-TET equivalents.\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import mido\n",
    "import sys\n",
    "import ast\n",
    "import traceback\n",
    "import os\n",
    "\n",
    "# --- CONVENTION MODULE IMPORT ---\n",
    "try:\n",
    "    from src import convention\n",
    "    print(\"‚úÖ Successfully imported src.convention\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import convention\n",
    "        print(\"‚úÖ Successfully imported convention\")\n",
    "    except ImportError:\n",
    "        # Fallback for when running from root without proper package context\n",
    "        sys.path.append(os.path.abspath(os.path.join(os.getcwd(), 'src')))\n",
    "        try:\n",
    "            import convention\n",
    "            print(\"‚úÖ Imported convention after path adjust\")\n",
    "        except ImportError:\n",
    "            print(\"‚ùå CRITICAL: convention module not found. Please ensure src/convention.py exists.\")\n",
    "\n",
    "# 53-TET Note Definitions (0-52)\n",
    "NOTE_NAMES_53TET = [\n",
    "    \"C\", \"^C\", \"^^C\", \"vvC#\", \"vC#\", \"C#\", \"^C#\", \"^^C#\", \"vD\", \"D\", \n",
    "    \"^D\", \"^^D\", \"vvD#\", \"vD#\", \"D#\", \"^^Eb\", \"vvE\", \"vE\", \"E\", \"^E\", \n",
    "    \"^^E\", \"vF\", \"F\", \"^F\", \"^^F\", \"vvF#\", \"vF#\", \"F#\", \"^F#\", \"^^F#\", \n",
    "    \"vG\", \"G\", \"^G\", \"^^G\", \"vvG#\", \"vG#\", \"G#\", \"^G#\", \"vvA\", \"vA\", \n",
    "    \"A\", \"^A\", \"^^A\", \"vBb\", \"Bb\", \"^Bb\", \"^^Bb\", \"vvB\", \"vB\", \"B\", \n",
    "    \"^B\", \"^^B\", \"vC\"\n",
    "]\n",
    "\n",
    "def identify_semantic_quality(steps):\n",
    "    \"\"\"\n",
    "    Returns the semantic name (e.g. 'supermajor') for the interval step count.\n",
    "    Uses the convention module's glossary.\n",
    "    \"\"\"\n",
    "    if steps is None: return None\n",
    "    steps = steps % 53\n",
    "    # Delegate to convention module\n",
    "    return convention.STEP_TO_SEMANTIC.get(steps, f\"step{steps}\")\n",
    "\n",
    "def get_new_chord_name(intervals_in_steps):\n",
    "    \"\"\"\n",
    "    Delegates naming to the convention module logic.\n",
    "    \"\"\"\n",
    "    q3 = identify_semantic_quality(intervals_in_steps.get('third'))\n",
    "    q5 = identify_semantic_quality(intervals_in_steps.get('fifth'))\n",
    "    q7 = identify_semantic_quality(intervals_in_steps.get('seventh'))\n",
    "    \n",
    "    # Use the convention's sophisticated naming logic\n",
    "    return convention.get_name(q3, q5, q7)\n",
    "\n",
    "\n",
    "# Text processing dependencies\n",
    "try:\n",
    "    from src import chord_mapping\n",
    "    print(\"Successfully imported src.chord_mapping\")\n",
    "except ImportError:\n",
    "    try:\n",
    "        import chord_mapping\n",
    "        print(\"Successfully imported chord_mapping\")\n",
    "    except ImportError:\n",
    "        # If running from src directly without package context\n",
    "        current_dir = Path.cwd()\n",
    "        if (current_dir / \"chord_mapping.py\").exists():\n",
    "            sys.path.append(str(current_dir))\n",
    "            import chord_mapping\n",
    "            print(\"Imported chord_mapping from current directory\")\n",
    "        else:\n",
    "            print(\"Warning: Could not import chord_mapping. Text conversion will still work using internal definitions.\")\n",
    "\n",
    "# Modal scale type definitions\n",
    "MODAL_SCALE_TYPES = {\n",
    "    'type_0': {\n",
    "        'name': 'Major',\n",
    "        'hc_distances': [0, 9, 9, 4, 9, 9, 9],  # Standard 12-TET\n",
    "        'description': 'Standard major scale (baseline 12-TET)'\n",
    "    },\n",
    "    'type_1': {\n",
    "        'name': 'Neutral',\n",
    "        'hc_distances': [0, 8, 7, 7, 9, 8, 7],\n",
    "        'description': 'Neutral mode with neutral intervals'\n",
    "    },\n",
    "    'type_2': {\n",
    "        'name': 'SubMinor',\n",
    "        'hc_distances': [0, 9, 3, 10, 9, 3, 10],\n",
    "        'description': 'Subminor mode'\n",
    "    },\n",
    "    'type_3': {\n",
    "        'name': 'H_3rd_H_7th',\n",
    "        'hc_distances': [0, 9, 8, 5, 9, 8, 5],\n",
    "        'description': 'Harmonic 3rd and 7th mode'\n",
    "    },\n",
    "    'type_4': {\n",
    "        'name': 'UpMajor',\n",
    "        'hc_distances': [0, 10, 9, 3, 9, 10, 9],\n",
    "        'description': 'Up-major mode'\n",
    "    },\n",
    "    'type_5': {\n",
    "        'name': 'Major_v2',\n",
    "        'hc_distances': [0, 9, 9, 5, 8, 8, 9],\n",
    "        'description': 'Alternative major mode'\n",
    "    },\n",
    "    'type_6': {\n",
    "        'name': 'Neutral_N',\n",
    "        'hc_distances': [0, 8, 7, 7, 9, 5, 10],\n",
    "        'description': 'Neutral N mode'\n",
    "    }\n",
    "}\n",
    "\n",
    "def get_53tet_ratio(steps):\n",
    "    return 2 ** (steps / 53.0)\n",
    "\n",
    "def find_closest_53tet_step(ratio):\n",
    "    steps = round(53 * np.log2(ratio))\n",
    "    return steps\n",
    "\n",
    "def build_chromatic_scale_53tet(hc_distances, root_step=0, tonic_position=0):\n",
    "    scale_7_steps = np.cumsum(hc_distances)\n",
    "    relative_positions = [0, 2, 4, 5, 7, 9, 11]\n",
    "    scale_positions = [(pos + tonic_position) % 12 for pos in relative_positions]\n",
    "    chromatic_steps = [None] * 12\n",
    "    for i, pos in enumerate(scale_positions):\n",
    "        chromatic_steps[pos] = root_step + scale_7_steps[i]\n",
    "    for i in range(12):\n",
    "        if chromatic_steps[i] is None:\n",
    "            prev_pos = -1\n",
    "            next_pos = 12\n",
    "            for j in range(i - 1, -1, -1):\n",
    "                if chromatic_steps[j] is not None:\n",
    "                    prev_pos = j\n",
    "                    break\n",
    "            for j in range(i + 1, 12):\n",
    "                if chromatic_steps[j] is not None:\n",
    "                    next_pos = j\n",
    "                    break\n",
    "            if prev_pos >= 0 and next_pos < 12:\n",
    "                prev_step = chromatic_steps[prev_pos]\n",
    "                next_step = chromatic_steps[next_pos]\n",
    "                range_steps = next_step - prev_step\n",
    "                positions = next_pos - prev_pos\n",
    "                offset = i - prev_pos\n",
    "                chromatic_steps[i] = round(prev_step + (range_steps * offset / positions))\n",
    "            elif prev_pos >= 0:\n",
    "                prev_step = chromatic_steps[prev_pos]\n",
    "                range_steps = (root_step + 53) - prev_step\n",
    "                positions = 12 - prev_pos\n",
    "                offset = i - prev_pos\n",
    "                chromatic_steps[i] = round(prev_step + (range_steps * offset / positions))\n",
    "            else:\n",
    "                chromatic_steps[i] = root_step + round((i / 12) * 53)\n",
    "    return chromatic_steps\n",
    "\n",
    "def calculate_53tet_frequency(midi_note, chromatic_scale_steps):\n",
    "    tet12_freq = 440.0 * (2 ** ((midi_note - 69) / 12))\n",
    "    note_in_octave = midi_note % 12\n",
    "    step_53tet = chromatic_scale_steps[note_in_octave]\n",
    "    step_12tet = (note_in_octave * 53) / 12\n",
    "    hc_deviation = step_53tet - step_12tet\n",
    "    ratio = 2 ** (hc_deviation / 53)\n",
    "    frequency = tet12_freq * ratio\n",
    "    return frequency\n",
    "\n",
    "def calculate_pitch_bend_for_frequency(target_freq, midi_note):\n",
    "    a4_freq = 440.0\n",
    "    a4_midi = 69\n",
    "    tet12_freq = a4_freq * (2 ** ((midi_note - a4_midi) / 12))\n",
    "    if tet12_freq > 0:\n",
    "        cents = 1200 * np.log2(target_freq / tet12_freq)\n",
    "    else:\n",
    "        cents = 0\n",
    "    return cents\n",
    "\n",
    "def process_text_file_conversion(input_path, scale_type, key, chromatic_scale, output_dir=None):\n",
    "    \"\"\"\n",
    "    Finds the corresponding text file for a MIDI file and converts its chords to 53-TET notation.\n",
    "    \"\"\"\n",
    "    print(f\"DEBUG: process_text_file_conversion called for {input_path}\")\n",
    "    \n",
    "    # Locate text directory\n",
    "    potential_text_dirs = [\n",
    "        input_path.parent.parent.parent / \"text_files\", \n",
    "        input_path.parent.parent / \"text_files\",        \n",
    "        Path(\"dataset/text_files\").resolve(),\n",
    "        Path(\"../dataset/text_files\").resolve()\n",
    "    ]\n",
    "    \n",
    "    text_dir = None\n",
    "    for d in potential_text_dirs:\n",
    "        if d.exists():\n",
    "            text_dir = d\n",
    "            break\n",
    "            \n",
    "    if text_dir is None:\n",
    "        print(\"‚ö†Ô∏è Could not locate text_files directory.\")\n",
    "        return\n",
    "\n",
    "    text_filename = input_path.stem + \".txt\"\n",
    "    text_path = text_dir / text_filename\n",
    "    \n",
    "    if not text_path.exists():\n",
    "        text_filename_alt = input_path.stem.split(\"_type\")[0] + \".txt\" \n",
    "        text_path_alt = text_dir / text_filename_alt\n",
    "        if text_path_alt.exists():\n",
    "             text_path = text_path_alt\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è Corresponding text file not found: {text_path}\")\n",
    "            return\n",
    "        \n",
    "    print(f\"üìÑ Processing text file: {text_path.name}\")\n",
    "    \n",
    "    try:\n",
    "        with open(text_path, 'r') as f:\n",
    "            content = f.read()\n",
    "            try:\n",
    "                chord_data = ast.literal_eval(content)\n",
    "            except:\n",
    "                print(\"Could not parse text file as list structure\")\n",
    "                return\n",
    "            \n",
    "        modified_chords = []\n",
    "        \n",
    "        chromatic_map = {\n",
    "            'C': 0, 'C#': 1, 'Db': 1, 'D': 2, 'D#': 3, 'Eb': 3,\n",
    "            'E': 4, 'F': 5, 'F#': 6, 'Gb': 6, 'G': 7, 'G#': 8,\n",
    "            'Ab': 8, 'A': 9, 'A#': 10, 'Bb': 10, 'B': 11\n",
    "        }\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(chord_data):\n",
    "            token = chord_data[i]\n",
    "            \n",
    "            # Handle Slash chords (Bass note) \n",
    "            if token == '/':\n",
    "                modified_chords.append(token)\n",
    "                i += 1\n",
    "                if i < len(chord_data):\n",
    "                    bass_token = chord_data[i]\n",
    "                    if bass_token in chromatic_map:\n",
    "                         bass_idx = chromatic_map[bass_token]\n",
    "                         bass_step = chromatic_scale[bass_idx]\n",
    "                         new_bass_name = NOTE_NAMES_53TET[bass_step]\n",
    "                         modified_chords.append(new_bass_name)\n",
    "                    else:\n",
    "                         modified_chords.append(bass_token) \n",
    "                    i += 1\n",
    "                continue\n",
    "\n",
    "            # Check for Root match\n",
    "            is_root = False\n",
    "            root_text = \"\"\n",
    "            \n",
    "            if token in chromatic_map:\n",
    "                is_root = True\n",
    "                root_text = token\n",
    "            \n",
    "            if not is_root:\n",
    "                modified_chords.append(token)\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            # Found Root\n",
    "            quality_text = \"\"\n",
    "            has_quality_token = False\n",
    "            current_idx = i\n",
    "            \n",
    "            if current_idx + 1 < len(chord_data):\n",
    "                next_tok = chord_data[current_idx + 1]\n",
    "                if (next_tok not in ['|', '|:', ':|', 'e||', 'b||', '/', '.'] \n",
    "                    and not next_tok.startswith('Form_')\n",
    "                    and not (next_tok.replace('.','',1).isdigit())): \n",
    "                    \n",
    "                    quality_text = next_tok\n",
    "                    has_quality_token = True\n",
    "            \n",
    "            # Parse Intervals\n",
    "            input_intervals = {\n",
    "                'third': 4, \n",
    "                'fifth': 7, \n",
    "                'seventh': None \n",
    "            }\n",
    "            \n",
    "            q = quality_text\n",
    "            if 'maj7' in q or 'Maj7' in q:\n",
    "                input_intervals['seventh'] = 11\n",
    "            elif 'maj' in q: \n",
    "                pass\n",
    "            elif 'dom7' in q or q == '7':\n",
    "                input_intervals['seventh'] = 10\n",
    "            elif 'm7' in q or 'min7' in q: \n",
    "                input_intervals['third'] = 3\n",
    "                input_intervals['seventh'] = 10\n",
    "            elif 'm' in q or 'min' in q:\n",
    "                input_intervals['third'] = 3\n",
    "                if '7' in q: input_intervals['seventh'] = 10 \n",
    "            elif 'dim' in q or '√∏' in q:\n",
    "                input_intervals['third'] = 3\n",
    "                input_intervals['fifth'] = 6\n",
    "                if '7' in q: input_intervals['seventh'] = 9 \n",
    "                if '√∏' in q: input_intervals['seventh'] = 10 \n",
    "            elif 'aug' in q or '+' in q:\n",
    "                input_intervals['fifth'] = 8\n",
    "                if '7' in q: input_intervals['seventh'] = 10\n",
    "                \n",
    "            # Calculate 53-TET steps\n",
    "            root_idx_12 = chromatic_map[root_text]\n",
    "            root_step = chromatic_scale[root_idx_12]\n",
    "            \n",
    "            def get_step_from_12tet_interval(root_step, interval_12):\n",
    "                target_idx_12 = (root_idx_12 + interval_12) % 12\n",
    "                target_step = chromatic_scale[target_idx_12]\n",
    "                diff = target_step - root_step\n",
    "                if diff < 0: diff += 53\n",
    "                return diff\n",
    "\n",
    "            steps_map = {}\n",
    "            steps_map['third'] = get_step_from_12tet_interval(root_step, input_intervals['third'])\n",
    "            steps_map['fifth'] = get_step_from_12tet_interval(root_step, input_intervals['fifth'])\n",
    "            \n",
    "            if input_intervals['seventh'] is not None:\n",
    "                steps_map['seventh'] = get_step_from_12tet_interval(root_step, input_intervals['seventh'])\n",
    "            else:\n",
    "                steps_map['seventh'] = None\n",
    "                \n",
    "            # Get New Suffix\n",
    "            new_suffix = get_new_chord_name(steps_map)\n",
    "            \n",
    "            new_root_name = NOTE_NAMES_53TET[root_step]\n",
    "            modified_chords.append(new_root_name)\n",
    "            modified_chords.append(new_suffix)\n",
    "            \n",
    "            if has_quality_token:\n",
    "                i += 2 \n",
    "            else:\n",
    "                i += 1 \n",
    "\n",
    "        if output_dir is None:\n",
    "             output_path_dir = input_path.parent\n",
    "        else:\n",
    "             output_path_dir = output_dir\n",
    "\n",
    "        output_text_filename = f\"{input_path.stem}_{scale_type}.txt\"\n",
    "        output_text_path = output_path_dir / output_text_filename\n",
    "        \n",
    "        with open(output_text_path, 'w') as f:\n",
    "            f.write(str(modified_chords))\n",
    "            \n",
    "        print(f\"‚úÖ Text conversion saved: {output_text_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing text file: {e}\")\n",
    "        traceback.print_exc()\n",
    "\n",
    "def convert_midi_to_53tet(input_midi_path, scale_type='type_1', output_dir=None, key=None):\n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"53-TET MODAL CONVERSION: {scale_type}\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    input_path = Path(input_midi_path)\n",
    "    if scale_type not in MODAL_SCALE_TYPES:\n",
    "        raise ValueError(f\"Unknown scale type: {scale_type}\")\n",
    "    \n",
    "    if key is None:\n",
    "        import re\n",
    "        match = re.search(r'_([A-G][#b]?)_(?:major|minor)', input_path.stem)\n",
    "        if match:\n",
    "            key = match.group(1)\n",
    "        else:\n",
    "            key = 'C'\n",
    "            print(f\"‚ö†Ô∏è  Could not detect key from filename, defaulting to C\")\n",
    "    \n",
    "    key_to_position = {\n",
    "        'C': 0, 'C#': 1, 'Db': 1, 'D': 2, 'D#': 3, 'Eb': 3,\n",
    "        'E': 4, 'F': 5, 'F#': 6, 'Gb': 6, 'G': 7, 'G#': 8,\n",
    "        'Ab': 8, 'A': 9, 'A#': 10, 'Bb': 10, 'B': 11\n",
    "    }\n",
    "    \n",
    "    tonic_position = key_to_position.get(key, 0)\n",
    "    config = MODAL_SCALE_TYPES[scale_type]\n",
    "    hc_distances = config['hc_distances']\n",
    "    \n",
    "    print(f\"Key: {key} (tonic at chromatic position {tonic_position})\")\n",
    "    print(f\"Scale: {config['name']}\")\n",
    "    \n",
    "    chromatic_scale = build_chromatic_scale_53tet(hc_distances, root_step=0, tonic_position=tonic_position)\n",
    "    \n",
    "    mid = mido.MidiFile(input_path)\n",
    "    mpe_midi = mido.MidiFile(type=mid.type, ticks_per_beat=mid.ticks_per_beat)\n",
    "    channel_pool = list(range(1, 16))\n",
    "    channel_index = 0\n",
    "    \n",
    "    print(\"Processing MIDI tracks...\")\n",
    "    \n",
    "    for track_idx, track in enumerate(mid.tracks):\n",
    "        new_track = mido.MidiTrack()\n",
    "        mpe_midi.tracks.append(new_track)\n",
    "        \n",
    "        for msg in track:\n",
    "            if msg.is_meta:\n",
    "                new_track.append(msg.copy())\n",
    "            else:\n",
    "                break\n",
    "        \n",
    "        for ch in range(1, 16):\n",
    "            if ch == 9: continue\n",
    "            new_track.append(mido.Message('control_change', control=101, value=0, time=0, channel=ch))\n",
    "            new_track.append(mido.Message('control_change', control=100, value=0, time=0, channel=ch))\n",
    "            new_track.append(mido.Message('control_change', control=6, value=2, time=0, channel=ch))\n",
    "            new_track.append(mido.Message('control_change', control=38, value=0, time=0, channel=ch))\n",
    "            new_track.append(mido.Message('control_change', control=101, value=127, time=0, channel=ch))\n",
    "            new_track.append(mido.Message('control_change', control=100, value=127, time=0, channel=ch))\n",
    "        \n",
    "        active_notes = {}\n",
    "        \n",
    "        for msg in track:\n",
    "            if msg.is_meta: continue\n",
    "            \n",
    "            if msg.type == 'note_on' and msg.velocity > 0:\n",
    "                target_freq = calculate_53tet_frequency(msg.note, chromatic_scale)\n",
    "                bend_cents = calculate_pitch_bend_for_frequency(target_freq, msg.note)\n",
    "                mpe_channel = channel_pool[channel_index % len(channel_pool)]\n",
    "                channel_index += 1\n",
    "                active_notes[msg.note] = (mpe_channel, msg.time, bend_cents)\n",
    "                bend_value = int((bend_cents / 200) * 8192)\n",
    "                bend_value = max(-8192, min(8191, bend_value))\n",
    "                new_track.append(mido.Message('pitchwheel', pitch=bend_value, time=msg.time, channel=mpe_channel))\n",
    "                new_track.append(mido.Message('note_on', note=msg.note, velocity=msg.velocity, time=0, channel=mpe_channel))\n",
    "            \n",
    "            elif msg.type == 'note_off' or (msg.type == 'note_on' and msg.velocity == 0):\n",
    "                if msg.note in active_notes:\n",
    "                    mpe_channel, start_time, bend_cents = active_notes[msg.note]\n",
    "                    new_track.append(mido.Message('note_off', note=msg.note, velocity=msg.velocity if msg.type == 'note_off' else 0, time=msg.time, channel=mpe_channel))\n",
    "                    del active_notes[msg.note]\n",
    "                else:\n",
    "                    new_track.append(msg.copy())\n",
    "            else:\n",
    "                new_track.append(msg.copy())\n",
    "    \n",
    "    # Process corresponding Text file\n",
    "    # Pass output_dir to ensure text file lands next to MIDI\n",
    "    process_text_file_conversion(input_path, scale_type, key, chromatic_scale, output_dir)\n",
    "\n",
    "    if output_dir is None:\n",
    "        output_dir = input_path.parent\n",
    "    else:\n",
    "        output_dir = Path(output_dir)\n",
    "        output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    output_filename = f\"{input_path.stem}_{scale_type}.mid\"\n",
    "    output_path = output_dir / output_filename\n",
    "    \n",
    "    mpe_midi.save(output_path)\n",
    "    print(f\"‚úÖ Conversion complete! Saved to {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "34aa2edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "53-TET MODAL CONVERSION: type_3\n",
      "======================================================================\n",
      "\n",
      "Key: C (tonic at chromatic position 0)\n",
      "Scale: H_3rd_H_7th\n",
      "Processing MIDI tracks...\n",
      "DEBUG: process_text_file_conversion called for /Users/david/ANIMA_Data_Formation/dataset/midi_files/mpe/47832_Something_C_major.mid\n",
      "üìÑ Processing text file: 47832_Something_C_major.txt\n",
      "‚úÖ Text conversion saved: /Users/david/ANIMA_Data_Formation/dataset/midi_files/47832_Something_C_major_type_3.txt\n",
      "‚úÖ Conversion complete! Saved to /Users/david/ANIMA_Data_Formation/dataset/midi_files/47832_Something_C_major_type_3.mid\n",
      "\n",
      "======================================================================\n",
      "‚úÖ CONVERSION COMPLETE\n",
      "======================================================================\n",
      "\n",
      "Original (12-TET): 47832_Something_C_major.mid\n",
      "Converted (53-TET type): 47832_Something_C_major_type_3.mid\n",
      "Corresponding Text File: 47832_Something_C_major_type_3.txt (check dataset/text_files)\n",
      "\n",
      "üìÅ Location: /Users/david/ANIMA_Data_Formation/dataset/midi_files\n"
     ]
    }
   ],
   "source": [
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# TEST: Convert \"Something\" to any type\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "# Input: \"Something\" by The Beatles (test case)\n",
    "input_midi = Path('/Users/david/ANIMA_Data_Formation/dataset/midi_files/mpe/47832_Something_C_major.mid')\n",
    "\n",
    "scale_type = \"type_3\"\n",
    "# Convert\n",
    "type_output = convert_midi_to_53tet(\n",
    "    input_midi_path=input_midi,\n",
    "    scale_type=scale_type,\n",
    "    output_dir=Path(\"/Users/david/ANIMA_Data_Formation/dataset/midi_files\"),\n",
    ")\n",
    "\n",
    "print(f\"\\n{'='*70}\")\n",
    "print(\"‚úÖ CONVERSION COMPLETE\")\n",
    "print(f\"{'='*70}\")\n",
    "print(f\"\\nOriginal (12-TET): {input_midi.name}\")\n",
    "print(f\"Converted (53-TET type): {type_output.name}\")\n",
    "print(f\"Corresponding Text File: {type_output.stem}.txt (check dataset/text_files)\")\n",
    "print(f\"\\nüìÅ Location: {type_output.parent}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20eb22f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Listen to the audio output to verify the conversion!\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "# ROBUST MPE RENDERER - Correct Timing & Synthesis\n",
    "# ‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê\n",
    "\n",
    "import numpy as np\n",
    "from scipy.io import wavfile\n",
    "import mido\n",
    "\n",
    "\n",
    "def render_mpe_to_wav(midi_path, output_wav=None, sample_rate=44100, speed=1.2):\n",
    "    \"\"\"\n",
    "    Renders MPE MIDI to WAV with correct timing, pitch bends, and ADSR envelope.\n",
    "    Args:\n",
    "        speed: Playback speed factor (1.0 = original, 1.5 = 50% faster, etc.)\n",
    "    \"\"\"\n",
    "    print(f\"Loading {midi_path.name}...\")\n",
    "    mid = mido.MidiFile(midi_path)\n",
    "\n",
    "    # Storage for note events: (start_time, duration, frequency, velocity)\n",
    "    note_events = []\n",
    "\n",
    "    # State tracking\n",
    "    channel_bends = {i: 0.0 for i in range(16)}\n",
    "    active_notes = {}\n",
    "\n",
    "    current_time = 0.0\n",
    "\n",
    "    # Parse MIDI messages\n",
    "    for msg in mid:\n",
    "        current_time += msg.time / speed\n",
    "\n",
    "        if msg.type == \"pitchwheel\":\n",
    "            # Pitch Bend Range: +/- 2 semitones (+/- 200 cents)\n",
    "            cents = (msg.pitch / 8192.0) * 200.0\n",
    "            channel_bends[msg.channel] = cents\n",
    "\n",
    "        elif msg.type == \"note_on\" and msg.velocity > 0:\n",
    "            bend_cents = channel_bends.get(msg.channel, 0.0)\n",
    "            base_freq = 440.0 * (2 ** ((msg.note - 69) / 12.0))\n",
    "            freq = base_freq * (2 ** (bend_cents / 1200.0))\n",
    "\n",
    "            active_notes[(msg.channel, msg.note)] = (\n",
    "                current_time,\n",
    "                freq,\n",
    "                msg.velocity / 127.0,\n",
    "            )\n",
    "\n",
    "        elif msg.type == \"note_off\" or (msg.type == \"note_on\" and msg.velocity == 0):\n",
    "            key = (msg.channel, msg.note)\n",
    "            if key in active_notes:\n",
    "                start_time, freq, vel = active_notes.pop(key)\n",
    "                duration = current_time - start_time\n",
    "                if duration > 0.005:\n",
    "                    note_events.append((start_time, duration, freq, vel))\n",
    "\n",
    "    if not note_events:\n",
    "        print(\"‚ö†Ô∏è No notes found to render!\")\n",
    "        return None\n",
    "\n",
    "    # --- ADSR Configuration (Natural Decay) ---\n",
    "    # To fix \"not decaying\" / \"beep\" sound:\n",
    "    # 1. Zero sustain so notes fade out even if held (Piano-like)\n",
    "    # 2. Longer decay time for natural fade\n",
    "    attack_time = 0.02  # Fast but soft attack\n",
    "    decay_time = 1.2  # Long decay (1s) to silence\n",
    "    sustain_level = 0.0  # No static sustain (prevents \"pure tone\" drone)\n",
    "    release_time = 0.95  # Gentle release on note off\n",
    "\n",
    "    total_duration = max(t + d for t, d, _, _ in note_events) + release_time + 0.5\n",
    "    print(\n",
    "        f\"Rendering {len(note_events)} notes. Total duration: {total_duration:.2f}s (Speed: {speed}x)\"\n",
    "    )\n",
    "\n",
    "    # Synthesis\n",
    "    num_samples = int(total_duration * sample_rate)\n",
    "    audio = np.zeros(num_samples, dtype=np.float32)\n",
    "\n",
    "    # Pre-calculate envelope lengths in samples\n",
    "    att_len = int(attack_time * sample_rate)\n",
    "    dec_len = int(decay_time * sample_rate)\n",
    "    rel_len = int(release_time * sample_rate)\n",
    "\n",
    "    for start, dur, freq, vel in note_events:\n",
    "        start_idx = int(start * sample_rate)\n",
    "        gate_len = int(dur * sample_rate)\n",
    "\n",
    "        # Buffer for this note (Gate + Release)\n",
    "        total_note_len = gate_len + rel_len\n",
    "        env = np.zeros(total_note_len, dtype=np.float32)\n",
    "\n",
    "        # We use a cursor to fill the buffer sequentially to ensure no overlaps overwrite incorrectly\n",
    "        cursor = 0\n",
    "\n",
    "        # 1. Attack Phase\n",
    "        # We attack for att_len, BUT we must stop if the gate ends before attack finishes\n",
    "        actual_att = min(att_len, gate_len)\n",
    "        if actual_att > 0:\n",
    "            env[0:actual_att] = np.linspace(0.0, 1.0, actual_att, endpoint=False)\n",
    "            cursor += actual_att\n",
    "\n",
    "        current_val = 1.0\n",
    "        # If the gate was shorter than the attack, we didn't reach 1.0.\n",
    "        if gate_len < att_len:\n",
    "            current_val = float(actual_att) / att_len\n",
    "\n",
    "        # 2. Decay Phase\n",
    "        # Only happens if we are still within the gate\n",
    "        remaining_gate = gate_len - cursor\n",
    "        if remaining_gate > 0:\n",
    "            # We decay from current_val down to sustain_level over dec_len\n",
    "            # But again, the gate might end during decay\n",
    "            actual_dec = min(dec_len, remaining_gate)\n",
    "\n",
    "            # Create decay curve\n",
    "            # Linear interpolation from current_val to sustain_level\n",
    "            decay_curve = np.linspace(\n",
    "                current_val, sustain_level, dec_len, endpoint=False\n",
    "            )\n",
    "\n",
    "            # Take what fits\n",
    "            env[cursor : cursor + actual_dec] = decay_curve[:actual_dec]\n",
    "            cursor += actual_dec\n",
    "\n",
    "            # Update current value for next stage\n",
    "            if actual_dec == dec_len:\n",
    "                current_val = sustain_level\n",
    "            else:\n",
    "                current_val = decay_curve[actual_dec - 1]\n",
    "\n",
    "        # 3. Sustain Phase\n",
    "        remaining_gate = gate_len - cursor\n",
    "        if remaining_gate > 0:\n",
    "            env[cursor : cursor + remaining_gate] = current_val\n",
    "            cursor += remaining_gate\n",
    "\n",
    "        # 4. Release Phase\n",
    "        # Fade from current_val to 0.0 over release_time\n",
    "        # We start writing at 'gate_len'\n",
    "        env[gate_len : gate_len + rel_len] = np.linspace(\n",
    "            current_val, 0.0, rel_len, endpoint=False\n",
    "        )\n",
    "\n",
    "        # Make sure we don't go out of bounds of the main audio buffer\n",
    "        end_idx = start_idx + len(env)\n",
    "        if end_idx > num_samples:\n",
    "            # Trim env if it goes past end of audio buffer\n",
    "            env = env[: num_samples - start_idx]\n",
    "            end_idx = num_samples\n",
    "\n",
    "        # Generate Phase-locked Oscillator (Odd harmonics for \"clarinet/triangle\" generic sound)\n",
    "        t = np.arange(len(env)) / sample_rate\n",
    "        p = 2 * np.pi * freq * t\n",
    "\n",
    "        # Fundamental + Odd harmonics with alternating signs (approximation of triangle/clarinet)\n",
    "        # sin(x) - 0.11 sin(3x) + 0.04 sin(5x)\n",
    "        osc = (1.0 * np.sin(p)) - (0.11 * np.sin(3 * p)) + (0.04 * np.sin(5 * p))\n",
    "\n",
    "        # Add to main buffer\n",
    "        # Reduced amplitude slightly to prevent summing clipping\n",
    "        audio[start_idx:end_idx] += osc * env * vel * 0.15\n",
    "\n",
    "    # Normalize\n",
    "    peak = np.max(np.abs(audio))\n",
    "    if peak > 0:\n",
    "        audio = audio / peak * 0.95\n",
    "\n",
    "    audio_int16 = (audio * 32767).astype(np.int16)\n",
    "    if output_wav is None:\n",
    "        output_wav = midi_path.with_suffix(\".wav\")\n",
    "\n",
    "    wavfile.write(output_wav, sample_rate, audio_int16)\n",
    "    print(f\"‚úÖ Audio saved: {output_wav}\")\n",
    "    return output_wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e37c523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 47832_Something_C_major_type_3.mid...\n",
      "Rendering 825 notes. Total duration: 311.45s (Speed: 1.2x)\n"
     ]
    }
   ],
   "source": [
    "# play the audio file\n",
    "# Run it\n",
    "wav_file = render_mpe_to_wav(type_output)\n",
    "print(f\"Run in terminal: open '{wav_file}'\")\n",
    "\n",
    "# Play in Notebook\n",
    "print(\"\\nüéß Audio Player:\")\n",
    "from IPython.display import Audio, display\n",
    "\n",
    "display(Audio(wav_file))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
